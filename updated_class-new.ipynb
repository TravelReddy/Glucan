{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV,Lasso,RidgeCV,Ridge,ElasticNetCV,ElasticNet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_ada_lasso(X_train,y_train,X_test):\n",
    "    \n",
    "    # apply ridge regression to determine the penalty weights\n",
    "    rcv = RidgeCV()\n",
    "    rcv.fit(X_train,y_train)\n",
    "    ridge_coefs = rcv.coef_\n",
    "    \n",
    "    # apply lasso with penalization\n",
    "    enet = ElasticNet(l1_ratio=1/abs(min(ridge_coefs)))\n",
    "    enet.fit(X_train,y_train)\n",
    "    impute_values = enet.predict(X_test)\n",
    "\n",
    "    return impute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_elastic_net(X_train,y_train,X_test):\n",
    "    enet = ElasticNet(alpha=0.5)\n",
    "    enet.fit(X_train,y_train)\n",
    "    \n",
    "    impute_values = enet.predict(X_test)\n",
    "    \n",
    "    return impute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_scad(X_train,y_train,X_test):\n",
    "    enet = ElasticNet(l1_ratio=3.7) # SCAD penalty default value\n",
    "    enet.fit(X_train,y_train)\n",
    "    impute_values = enet.predict(X_test)\n",
    "    \n",
    "    return impute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_excel('./clean_pls_predictors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucan</th>\n",
       "      <th>xylan</th>\n",
       "      <th>lignin</th>\n",
       "      <th>ash</th>\n",
       "      <th>Volatiles  db</th>\n",
       "      <th>Ash  db</th>\n",
       "      <th>Carbon  db</th>\n",
       "      <th>Nitrogen  db</th>\n",
       "      <th>ADSCI-growing season</th>\n",
       "      <th>ADSCI-30 days prior to harvest</th>\n",
       "      <th>...</th>\n",
       "      <th>50-100 Site SOM</th>\n",
       "      <th>50-100 Site Soil total organic carbon</th>\n",
       "      <th>50-100 Site Total Soil nitrogen</th>\n",
       "      <th>50-100 Site Extractable P mg kg-1</th>\n",
       "      <th>50-100 Site Extractable K mg kg-1</th>\n",
       "      <th>50-100 Site Extractable Ca mg kg-1</th>\n",
       "      <th>50-100 Site Extractable Mg mg kg-1</th>\n",
       "      <th>50-100 Site Extractable S mg kg-1</th>\n",
       "      <th>50-100 Site BD g cm-3</th>\n",
       "      <th>Nitrogen Trt Categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.193500</td>\n",
       "      <td>21.764114</td>\n",
       "      <td>19.238295</td>\n",
       "      <td>6.586029</td>\n",
       "      <td>81.223333</td>\n",
       "      <td>5.776667</td>\n",
       "      <td>47.813333</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>47.1</td>\n",
       "      <td>144</td>\n",
       "      <td>1613</td>\n",
       "      <td>154</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.410339</td>\n",
       "      <td>22.226731</td>\n",
       "      <td>21.094115</td>\n",
       "      <td>3.712055</td>\n",
       "      <td>82.440000</td>\n",
       "      <td>3.943333</td>\n",
       "      <td>48.763333</td>\n",
       "      <td>0.156667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>39.5</td>\n",
       "      <td>130</td>\n",
       "      <td>1686</td>\n",
       "      <td>177</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      glucan      xylan     lignin       ash  Volatiles  db   Ash  db  \\\n",
       "0  36.193500  21.764114  19.238295  6.586029      81.223333  5.776667   \n",
       "1  40.410339  22.226731  21.094115  3.712055      82.440000  3.943333   \n",
       "\n",
       "   Carbon  db  Nitrogen  db  ADSCI-growing season  \\\n",
       "0   47.813333      0.393333                   0.0   \n",
       "1   48.763333      0.156667                   0.0   \n",
       "\n",
       "   ADSCI-30 days prior to harvest  ...  50-100 Site SOM   \\\n",
       "0                             0.0  ...               1.9   \n",
       "1                             0.0  ...               1.9   \n",
       "\n",
       "   50-100 Site Soil total organic carbon   50-100 Site Total Soil nitrogen   \\\n",
       "0                                    1.11                              0.11   \n",
       "1                                    1.08                              0.11   \n",
       "\n",
       "   50-100 Site Extractable P mg kg-1  50-100 Site Extractable K mg kg-1  \\\n",
       "0                               47.1                                144   \n",
       "1                               39.5                                130   \n",
       "\n",
       "   50-100 Site Extractable Ca mg kg-1  50-100 Site Extractable Mg mg kg-1  \\\n",
       "0                                1613                                 154   \n",
       "1                                1686                                 177   \n",
       "\n",
       "   50-100 Site Extractable S mg kg-1  50-100 Site BD g cm-3  \\\n",
       "0                               17.1                   1.69   \n",
       "1                               17.4                   1.66   \n",
       "\n",
       "   Nitrogen Trt Categorical  \n",
       "0                         1  \n",
       "1                         1  \n",
       "\n",
       "[2 rows x 123 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAs_found = np.where(np.isnan(temp_X[:,4])==True)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.26533959305165"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(temp_X[:,4],NAs_found).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_missing_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(temp_X.shape[1]):\n",
    "    NAs_found = np.where(np.isnan(temp_X[:,col])==True)[0].tolist()\n",
    "    if len(NAs_found) != 0:\n",
    "        current_mean = np.delete(temp_X[:,col],NAs_found).mean()\n",
    "        temp_list = {i:current_mean for i in NAs_found}\n",
    "        temp_missing_data.update({str(col):temp_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mouse:\n",
    "    \n",
    "    def __init__(self,X,prediciton_algorithm,max_iterations,stopping_criterion):\n",
    "        self.X = X\n",
    "        self.prediciton_algorithm = prediciton_algorithm\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.X_mean = None\n",
    "        self.X_sd = None\n",
    "        self.y_mean = None\n",
    "        self.y_sd = None\n",
    "        self.current_column_name = None\n",
    "        self.current_column_index = None\n",
    "        self.max_iterations=max_iterations\n",
    "        self.stopping_criterion = stopping_criterion\n",
    "        self.iterations_performed = None,\n",
    "        \n",
    "        temp_X = np.array(self.X)\n",
    "#         print(self.X.shape)\n",
    "        self.n = self.X.shape[0]\n",
    "        self.p = self.X.shape[1]\n",
    "        \n",
    "        temp_missing_data = {}\n",
    "    \n",
    "        for col in range(temp_X.shape[1]):\n",
    "            NAs_found = np.where(np.isnan(temp_X[:,col])==True)[0].tolist()\n",
    "            if len(NAs_found) != 0:\n",
    "                current_mean = np.delete(temp_X[:,col],NAs_found).mean()\n",
    "                temp_list = {i:current_mean for i in NAs_found}\n",
    "                temp_X[NAs_found,col] = current_mean\n",
    "                temp_missing_data.update({str(col):temp_list})\n",
    "                \n",
    "        self.X = temp_X\n",
    "        self.q = len(temp_missing_data)\n",
    "        self.missing_data = temp_missing_data\n",
    "#         print(self.missing_data)\n",
    "        self.X_old = temp_X*100\n",
    "        \n",
    "        \n",
    "# Set_column_response function used for checking datatype and assing the value based on the datatype\n",
    "        \n",
    "    def set_column_response(self,input_index):\n",
    "        if type(input_index) == int:\n",
    "            self.current_column_name = str(input_index) \n",
    "            self.current_column_index = input_index\n",
    "#             print(self.current_column_name)\n",
    "            \n",
    "        else:\n",
    "            self.current_column_name = input_index\n",
    "            self.current_column_index = int(input_index)\n",
    "#             print(self.current_column_name)\n",
    "        \n",
    "            \n",
    "    \n",
    "# Dividing the data into training,test and finding mean and standard deviation\n",
    "    def set_data_split(self):\n",
    "        \n",
    "#         print(self.missing_data[self.current_column_name].keys())\n",
    "        \n",
    "        row_missing_index = self.missing_data[self.current_column_name].keys()\n",
    "                \n",
    "        ### X train ###\n",
    "        temp_X_train = np.delete(self.X,self.current_column_index,axis=1)\n",
    "        temp_X_train = np.delete(temp_X_train,list(row_missing_index),axis=0)\n",
    "\n",
    "        ### X test ###\n",
    "        temp_X_test = np.delete(self.X,self.current_column_index,axis=1)\n",
    "        temp_X_test = temp_X_test[list(row_missing_index),:]\n",
    "        \n",
    "        ### Y_train ###\n",
    "        temp_Y_train = np.delete(self.X,list(row_missing_index),axis=0)\n",
    "        temp_Y_train = temp_Y_train[:,self.current_column_index]\n",
    "\n",
    "        ### Y_test ###\n",
    "        temp_Y_test = self.X[list(row_missing_index),self.current_column_index]\n",
    "        \n",
    "        # center the data to the training set\n",
    "        # this will change with each iteration of imputation\n",
    "        self.X_mean = temp_X_train.mean()\n",
    "        self.X_sd = temp_X_train.std()\n",
    "\n",
    "        self.y_mean = temp_Y_train.mean()\n",
    "        self.y_sd = temp_Y_train.std()\n",
    "\n",
    "        self.y_train = (temp_Y_train - self.y_mean) / self.y_sd\n",
    "        self.y_test = (temp_Y_test - self.y_mean) / self.y_sd\n",
    "\n",
    "        temp_X_train = temp_X_train - self.X_mean\n",
    "        tem_X_test = temp_X_test - self.X_mean\n",
    "        \n",
    "        self.X_train = temp_X_train/self.X_sd\n",
    "        self.X_test = temp_X_test/self.X_sd\n",
    "        \n",
    "    \n",
    "    def update_X(self):\n",
    "        \n",
    "        row_missing_index =  self.missing_data[self.current_column_name].keys()\n",
    "        \n",
    "        for i in row_missing_index:\n",
    "            \n",
    "            self.missing_data[self.current_column_name][i] = self.y_test*self.y_sd*self.y_mean\n",
    "#         print(self.missing_data)\n",
    "        \n",
    "#         print(self.missing_data[self.current_column_name])\n",
    "        self.X[list(self.missing_data[self.current_column_name].keys()),self.current_column_index] = self.y_test\n",
    "      \n",
    "    \n",
    "# Update_X function updates the X matrix missing data wth y_pred.\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        for iters in range(self.max_iterations):\n",
    "            self.iterations_performed = iters\n",
    "            # 2. Regressing the missing values\n",
    "            # random starting point for the missing data column\n",
    "            \n",
    "            for k in self.missing_data.keys():\n",
    "                \n",
    "                self.set_column_response(k)\n",
    "                self.set_data_split()\n",
    "                self.y_test = self.prediciton_algorithm(self.X_train,self.y_train,self.X_test)\n",
    "                self.update_X()\n",
    "                \n",
    "            if np.linalg.norm(self.X - self.X_old) < self.stopping_criterion:\n",
    "                \n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                self.X_old = self.X\n",
    "            \n",
    "        return self.missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4': {195: array([73.14021642, 73.14021642, 73.14021642, 73.14021642, 73.14021642,\n",
       "         73.14021642, 73.14021642]),\n",
       "  199: array([73.14021642, 73.14021642, 73.14021642, 73.14021642, 73.14021642,\n",
       "         73.14021642, 73.14021642]),\n",
       "  200: array([73.14021642, 73.14021642, 73.14021642, 73.14021642, 73.14021642,\n",
       "         73.14021642, 73.14021642]),\n",
       "  206: array([73.14021642, 73.14021642, 73.14021642, 73.14021642, 73.14021642,\n",
       "         73.14021642, 73.14021642]),\n",
       "  212: array([73.14021642, 73.14021642, 73.14021642, 73.14021642, 73.14021642,\n",
       "         73.14021642, 73.14021642]),\n",
       "  213: array([73.14021642, 73.14021642, 73.14021642, 73.14021642, 73.14021642,\n",
       "         73.14021642, 73.14021642]),\n",
       "  214: array([73.14021642, 73.14021642, 73.14021642, 73.14021642, 73.14021642,\n",
       "         73.14021642, 73.14021642])},\n",
       " '5': {195: array([-2.10500757, -2.10500757, -2.10500757, -2.20634006, -2.31917545,\n",
       "         -2.31917545, -2.31917545]),\n",
       "  199: array([-2.10500757, -2.10500757, -2.10500757, -2.20634006, -2.31917545,\n",
       "         -2.31917545, -2.31917545]),\n",
       "  200: array([-2.10500757, -2.10500757, -2.10500757, -2.20634006, -2.31917545,\n",
       "         -2.31917545, -2.31917545]),\n",
       "  206: array([-2.10500757, -2.10500757, -2.10500757, -2.20634006, -2.31917545,\n",
       "         -2.31917545, -2.31917545]),\n",
       "  212: array([-2.10500757, -2.10500757, -2.10500757, -2.20634006, -2.31917545,\n",
       "         -2.31917545, -2.31917545]),\n",
       "  213: array([-2.10500757, -2.10500757, -2.10500757, -2.20634006, -2.31917545,\n",
       "         -2.31917545, -2.31917545]),\n",
       "  214: array([-2.10500757, -2.10500757, -2.10500757, -2.20634006, -2.31917545,\n",
       "         -2.31917545, -2.31917545])},\n",
       " '6': {195: array([-6.95616662, -6.95616662, -6.95616662, -4.85265911, -4.33400235,\n",
       "         -4.33400235, -4.33400235]),\n",
       "  199: array([-6.95616662, -6.95616662, -6.95616662, -4.85265911, -4.33400235,\n",
       "         -4.33400235, -4.33400235]),\n",
       "  200: array([-6.95616662, -6.95616662, -6.95616662, -4.85265911, -4.33400235,\n",
       "         -4.33400235, -4.33400235]),\n",
       "  206: array([-6.95616662, -6.95616662, -6.95616662, -4.85265911, -4.33400235,\n",
       "         -4.33400235, -4.33400235]),\n",
       "  212: array([-6.95616662, -6.95616662, -6.95616662, -4.85265911, -4.33400235,\n",
       "         -4.33400235, -4.33400235]),\n",
       "  213: array([-6.95616662, -6.95616662, -6.95616662, -4.85265911, -4.33400235,\n",
       "         -4.33400235, -4.33400235]),\n",
       "  214: array([-6.95616662, -6.95616662, -6.95616662, -4.85265911, -4.33400235,\n",
       "         -4.33400235, -4.33400235])},\n",
       " '7': {195: array([-0.02286969, -0.02286969, -0.02286969, -0.02286969, -0.02286969,\n",
       "         -0.02286969, -0.02286969]),\n",
       "  199: array([-0.02286969, -0.02286969, -0.02286969, -0.02286969, -0.02286969,\n",
       "         -0.02286969, -0.02286969]),\n",
       "  200: array([-0.02286969, -0.02286969, -0.02286969, -0.02286969, -0.02286969,\n",
       "         -0.02286969, -0.02286969]),\n",
       "  206: array([-0.02286969, -0.02286969, -0.02286969, -0.02286969, -0.02286969,\n",
       "         -0.02286969, -0.02286969]),\n",
       "  212: array([-0.02286969, -0.02286969, -0.02286969, -0.02286969, -0.02286969,\n",
       "         -0.02286969, -0.02286969]),\n",
       "  213: array([-0.02286969, -0.02286969, -0.02286969, -0.02286969, -0.02286969,\n",
       "         -0.02286969, -0.02286969]),\n",
       "  214: array([-0.02286969, -0.02286969, -0.02286969, -0.02286969, -0.02286969,\n",
       "         -0.02286969, -0.02286969])}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse_class = mouse(X,prediciton_algorithm=mod_ada_lasso,\n",
    "                    max_iterations=30,\n",
    "                    stopping_criterion=1e-5)\n",
    "mouse_class.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mice:\n",
    "    \n",
    "    def __init__(self,X,prediction_algorithm):\n",
    "        \n",
    "        self.X = X\n",
    "        self.prediction_algorithm = prediction_algorithm\n",
    "        self.num_replicates = 10\n",
    "        self.max_iterations = 30\n",
    "        self.stopping_criterion = 1e-5\n",
    "        self.list_of_replicates = {}\n",
    "        self.imputation_results = {}\n",
    "        self.imputation_metrics = {}\n",
    "        \n",
    "    def run(self):\n",
    "        mouse_class = mouse(X=self.X,prediciton_algorithm=self.prediction_algorithm,\n",
    "                            max_iterations=self.max_iterations,\n",
    "                            stopping_criterion=self.stopping_criterion)\n",
    "        for m in range(self.num_replicates):\n",
    "            self.list_of_replicates.update({m:mouse_class.run()})\n",
    "            \n",
    "#         print(self.list_of_replicates)\n",
    "    \n",
    "    # Double check with this code with Ross\n",
    "    \n",
    "    def collect(self):\n",
    "        \n",
    "        for i in range(self.num_replicates):\n",
    "            for j in self.list_of_replicates[i].keys():\n",
    "#                 print(j)\n",
    "                if len(self.imputation_results) == 0:\n",
    "                    \n",
    "                    temp_index = list(self.list_of_replicates[i][j].keys())\n",
    "                    temp_matrix = np.repeat(0,len(temp_index)*self.num_replicates).reshape(self.num_replicates,len(temp_index))\n",
    "                    temp_matrix = pd.DataFrame(temp_matrix,columns=temp_index)\n",
    "                    self.imputation_results.update({j:temp_matrix})\n",
    "                    \n",
    "                temp_value = self.list_of_replicates[i][j].values()\n",
    "                self.imputation_results.update({j:{i:temp_value}})\n",
    "                \n",
    "#         print(self.imputation_results)\n",
    "                \n",
    "    def set_summary_stats(self):\n",
    "        \n",
    "        if len(self.imputation_results) == 0:\n",
    "            self.collect()\n",
    "            \n",
    "        for j in self.imputation_results:\n",
    "#             print(list(list(self.imputation_results[j].values())[0])[0])\n",
    "            temp_result = {}\n",
    "            num_samples = len(self.imputation_results[j])\n",
    "            temp_result['mean'] = np.mean(list(list(self.imputation_results[j].values())[0])[0])\n",
    "            temp_result['sd'] = np.std(list(list(self.imputation_results[j].values())[0])[0])\n",
    "            \n",
    "            standard_error = 1.96*temp_result['sd']/np.sqrt(num_samples)\n",
    "            temp_result['upper_ci'] = temp_result['mean'] + standard_error\n",
    "            temp_result['lower_ci'] = temp_result['mean'] - standard_error\n",
    "            \n",
    "            self.imputation_metrics.update({j:temp_result})\n",
    "            \n",
    "        print(self.imputation_metrics)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_excel('./clean_pls_predictors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4': {'mean': 73.14021642320411, 'sd': 0.0, 'upper_ci': 73.14021642320411, 'lower_ci': 73.14021642320411}, '5': {'mean': -2.2112698761697493, 'sd': 0.09916089018128679, 'upper_ci': -2.016914531414427, 'lower_ci': -2.4056252209250717}, '6': {'mean': -5.531880862498007, 'sd': 1.245096138082086, 'upper_ci': -3.091492431857119, 'lower_ci': -7.972269293138895}, '7': {'mean': -0.022869689588973525, 'sd': 3.469446951953614e-18, 'upper_ci': -0.022869689588973518, 'lower_ci': -0.022869689588973532}}\n"
     ]
    }
   ],
   "source": [
    "mice_class = mice(X,prediction_algorithm=mod_ada_lasso)\n",
    "mice_class.run()\n",
    "mice_class.set_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
